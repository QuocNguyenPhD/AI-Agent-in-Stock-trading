{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "591d670d",
   "metadata": {},
   "source": [
    "# Bot Trader Using Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3006c0a",
   "metadata": {},
   "source": [
    "## Imports needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "825503e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import seaborn as sns\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from gym import spaces\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27790bce",
   "metadata": {},
   "source": [
    "## Create Stock Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "aeb247d9-0dc5-47c8-8d18-04d72c240f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StockTradingEnv(gym.Env):\n",
    "    def __init__(self, df):\n",
    "        super(StockTradingEnv, self).__init__()\n",
    "        self.df = df\n",
    "        self.n_steps = len(df)\n",
    "        self.current_step = 0\n",
    "\n",
    "        self.initial_balance = 600.0\n",
    "        self.balance = self.initial_balance\n",
    "        self.shares_held = 0\n",
    "\n",
    "        # Observation space: [price, balance, shares held]\n",
    "        self.observation_space = spaces.Box(low=0, high=np.inf, shape=(3,), dtype=np.float32)\n",
    "        # Action space: 0 = hold, 1 = buy, 2 = sell\n",
    "        self.action_space = spaces.Discrete(3)\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_step = 0\n",
    "        self.balance = self.initial_balance\n",
    "        self.shares_held = 0\n",
    "        return self._get_obs()\n",
    "\n",
    "    def _get_obs(self):\n",
    "        price = float(self.df.iloc[self.current_step]['Close'])\n",
    "        return np.array([price, self.balance, self.shares_held], dtype=np.float32)\n",
    "\n",
    "    def step(self, action):\n",
    "        price = float(self.df.iloc[self.current_step]['Close'])\n",
    "\n",
    "        # Simple buy/sell logic\n",
    "        if action == 1 and self.balance >= price: # Buy Share\n",
    "            self.shares_held += 1\n",
    "            self.balance -= price\n",
    "        elif action == 2 and self.shares_held > 0: # Sell Share\n",
    "            self.shares_held -= 1\n",
    "            self.balance += price\n",
    "\n",
    "        self.current_step += 1\n",
    "        done = self.current_step >= self.n_steps - 1\n",
    "        obs = self._get_obs()\n",
    "\n",
    "        # Reward = total assets gain/loss\n",
    "        total_assets = self.balance + self.shares_held * price\n",
    "        reward = total_assets - self.initial_balance\n",
    "\n",
    "        return obs, reward, done, {}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc78812",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "02c27ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "# Data split\n",
    "df = yf.download(\"RIVN\", start=\"2022-01-01\", end=\"2024-01-01\")\n",
    "df = df.reset_index()\n",
    "train_data, test_data = train_test_split(df, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2ff068",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "87e12b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n",
      "/var/folders/m9/nb_yw90n2mqclplgs5qgf1f80000gn/T/ipykernel_35081/75054348.py:24: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  price = float(self.df.iloc[self.current_step]['Close'])\n",
      "/var/folders/m9/nb_yw90n2mqclplgs5qgf1f80000gn/T/ipykernel_35081/75054348.py:28: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n",
      "  price = float(self.df.iloc[self.current_step]['Close'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 399       |\n",
      "|    ep_rew_mean     | -6.23e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 479       |\n",
      "|    iterations      | 1         |\n",
      "|    time_elapsed    | 4         |\n",
      "|    total_timesteps | 2048      |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 399          |\n",
      "|    ep_rew_mean          | -6.5e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 413          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 9            |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.800535e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.1         |\n",
      "|    explained_variance   | 4.51e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.07e+06     |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -5.29e-05    |\n",
      "|    value_loss           | 8.17e+06     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 399         |\n",
      "|    ep_rew_mean          | -6.95e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 401         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 15          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002215379 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.1        |\n",
      "|    explained_variance   | -8.39e-05   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.22e+06    |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.00137    |\n",
      "|    value_loss           | 1.2e+07     |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 399           |\n",
      "|    ep_rew_mean          | -7.09e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 409           |\n",
      "|    iterations           | 4             |\n",
      "|    time_elapsed         | 19            |\n",
      "|    total_timesteps      | 8192          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00056992844 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.1          |\n",
      "|    explained_variance   | 4.71e-06      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 5.79e+06      |\n",
      "|    n_updates            | 30            |\n",
      "|    policy_gradient_loss | -0.000526     |\n",
      "|    value_loss           | 1.2e+07       |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 399           |\n",
      "|    ep_rew_mean          | -7.26e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 400           |\n",
      "|    iterations           | 5             |\n",
      "|    time_elapsed         | 25            |\n",
      "|    total_timesteps      | 10240         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00029195056 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.09         |\n",
      "|    explained_variance   | -2.5e-06      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 7.18e+06      |\n",
      "|    n_updates            | 40            |\n",
      "|    policy_gradient_loss | -0.000296     |\n",
      "|    value_loss           | 1.45e+07      |\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "env = StockTradingEnv(df)\n",
    "env_train=StockTradingEnv(train_data)\n",
    "\n",
    "\n",
    "#Training the model\n",
    "model = PPO(\"MlpPolicy\", env_train, verbose=1)\n",
    "model.learn(total_timesteps=10000)\n",
    "\n",
    "\n",
    "obs = env.reset()\n",
    "done = False\n",
    "i=0;\n",
    "action_hist=[];\n",
    "states_hist=[];\n",
    "obs_hist=[];\n",
    "reward_hist=[];\n",
    "while not done:\n",
    "    action, states = model.predict(obs)\n",
    "    states_hist.append(states)\n",
    "    action_hist.append(action)\n",
    "    obs, reward, done, _ = env.step(action)\n",
    "    obs_hist.append(obs)\n",
    "    reward_hist.append(reward)\n",
    "    \n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3fc60914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Seaborn's style for a cleaner look\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Example data\n",
    "x = np.linspace(0, len(reward_hist), len(reward_hist))\n",
    "\n",
    "reward_hist_array=np.array(reward_hist)\n",
    "\n",
    "plt.figure(figsize=(10,5), tight_layout=\"tight\")\n",
    "plt.subplot(2,2,1)\n",
    "plt.plot(x, reward_hist_array+600, color='tab:blue', linewidth=2)\n",
    "\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Net worth over time', fontsize=16)\n",
    "plt.xlabel('Days', fontsize=14)\n",
    "plt.ylabel('Reward', fontsize=14)\n",
    "\n",
    "# Show legend\n",
    "\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.plot(range(len(df['Open'])),df['Open'], label= \"Opening Price\")\n",
    "\n",
    "plt.plot(range(len(df['High'])),df['High']+30, label=\"High Price+30\")\n",
    "\n",
    "plt.plot(range(len(df['Low'])),df['Low']-30,label=\"Low Price-30\")\n",
    "\n",
    "plt.title('price vs time', fontsize=16)\n",
    "plt.xlabel('Days', fontsize=14)\n",
    "plt.ylabel('Price', fontsize=14)\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "\n",
    "n=np.array(obs_hist)\n",
    "plt.plot(range(len(action_hist)), n[:,2], color=\"r\")\n",
    "plt.title(\"Number of Share Over Time\")\n",
    "plt.xlabel('Days', fontsize=14)\n",
    "plt.ylabel('Share', fontsize=14)\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "df_array=np.array(df)\n",
    "plt.plot(range(len(df_array[:,4])),600/np.array(df_array[0,4])*df_array[:,4])\n",
    "plt.title(\"Net Worth Of Hold over time\")\n",
    "\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "197f33f6-3a41-4819-a859-75a760ef0efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace3cd01-3502-4e3e-b6da-da8345741de3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c3a049-b7a6-4a04-aebf-14488cf9edc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752e6dd8-5c97-45be-a411-0addd0a4e830",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
